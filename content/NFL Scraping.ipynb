{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "College Stats from Sports References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--user-data-dir=C:/Users/d_lasc01/AppData/Local/Google/Chrome/User Data/Profile 1')\n",
    "chrome_options.add_argument(\"--disable-extensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "pos_ranking_url = 'https://www.sports-reference.com/cfb/schools/'\n",
    "driver.get(pos_ranking_url)\n",
    "\n",
    "t = driver.find_elements_by_css_selector(\"#schools > tbody > tr > td[data-stat='school_name'] > a\")\n",
    "\n",
    "c = driver.find_elements_by_css_selector(\"#schools > tbody > tr > td[data-stat='year_max']\")\n",
    "\n",
    "schools = []\n",
    "for i in range(len(t)):\n",
    "    if int(c[i].text) >= 2017:\n",
    "        schools.append(re.findall('/schools/(.*)/', t[i].get_attribute(\"href\"))[0])\n",
    "    else: continue\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" year=tuple(range(2010,2022))\n",
    "col_stats = dict.fromkeys(schools)\n",
    "\n",
    "for school in schools:\n",
    "    col_stats[school] = dict.fromkeys(year) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" tables = ['passing', 'rushing_and_receiving', 'defense_and_fumbles', 'kicking_and_punting', 'scoring']\n",
    "\n",
    "for school in schools:\n",
    "    for yr in year:\n",
    "        col_stats[school][yr] = dict.fromkeys(tables) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pure selenium solution slower --> hidden if code needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from tqdm import tqdm\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "column_n = [['Player','Games', 'Completions', 'Attempts', 'Percentage', 'Yards', 'Y/A', 'AY/A', 'TD', 'INT', 'Rate'],\n",
    "            ['Player', 'Games', 'Attempts', 'R_Yards', 'R_AVG', 'R_TD', 'Catches', 'C_Yards', 'C_AVG', 'C_TD', 'S_Plays', 'S_YDS', 'S_AVG' ,'S_TD'],\n",
    "            ['Player', 'Games', 'Solo', 'Assist', 'Tot', 'Loss', 'Sack', 'INT', 'INT_Y', 'INT_AVG_Y', 'INT_TD', 'PD', 'Fum_Rec', 'Fum_Y', 'Fum_TD', 'Fum_Forc'],\n",
    "            ['Player', 'Games', 'XPM', 'XPA', 'XP%', 'FGM', 'FGA', 'FG%','PTS', 'Punts', 'YDS', 'AVG'],\n",
    "            ['Player', 'Games', 'R_TD', 'C_TD', 'INT_TD', 'FR_TD', 'PR_TD', 'KR_TD', 'Other', 'Total', 'XPM', 'FGM', '2PM', 'Safety', 'Points']]\n",
    "\n",
    "ids = ['#passing', '#rushing_and_receiving', '#defense_and_fumbles', '#kicking_and_punting', '#scoring']\n",
    "\n",
    "for i in tqdm(range(len(schools)), position=1):\n",
    "    for j in tqdm(range(len(year)), position=0):\n",
    "\n",
    "        data_link = 'https://www.sports-reference.com/cfb/schools/{school}/{year}.html'.format(school = schools[i], year = year[j])\n",
    "        driver.get(data_link)\n",
    "\n",
    "        \n",
    "        for k in range(len(ids)):\n",
    "            table_id = driver.find_element_by_css_selector(ids[k])\n",
    "\n",
    "            rows = [[column_n[k]]]\n",
    "\n",
    "            for x in range(len(table_id.find_elements_by_css_selector(\"tbody > tr\"))):\n",
    "                row = []\n",
    "\n",
    "                for y in range(len(table_id.find_elements_by_css_selector(\"tbody>tr[data-row='0']>td\"))):\n",
    "                    #if table_id.find_elements_by_css_selector(\"tbody>tr[data-row='{no}']>td\".format(no=x)) == []:\n",
    "                    #    continue\n",
    "                    #else: row.append(table_id.find_elements_by_css_selector(\"tbody>tr[data-row='{no}']>td\".format(no=x))[y].text)\n",
    "                    \n",
    "                    try: row.append(table_id.find_elements_by_css_selector(\"tbody>tr[data-row='{no}']>td\".format(no=x))[y].text)\n",
    "                    except: continue\n",
    "                rows.append(row)\n",
    "\n",
    "            col_stats[schools[i]][year[j]][ids[k][1:]] = pd.DataFrame(rows[1:] , columns = rows[0]).dropna().reset_index(drop=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "%store col_stats\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "column_n = [['Player','Games', 'Completions', 'Attempts', 'Percentage', 'Yards', 'Y/A', 'AY/A', 'TD', 'INT', 'Rate'],\n",
    "            ['Player', 'Games', 'Attempts', 'R_Yards', 'R_AVG', 'R_TD', 'Catches', 'C_Yards', 'C_AVG', 'C_TD', 'S_Plays', 'S_YDS', 'S_AVG' ,'S_TD'],\n",
    "            ['Player', 'Games', 'Solo', 'Assist', 'Tot', 'Loss', 'Sack', 'INT', 'INT_Y', 'INT_AVG_Y', 'INT_TD', 'PD', 'Fum_Rec', 'Fum_Y', 'Fum_TD', 'Fum_Forc'],\n",
    "            ['Player', 'Games', 'XPM', 'XPA', 'XP%', 'FGM', 'FGA', 'FG%','PTS', 'Punts', 'YDS', 'AVG'],\n",
    "            ['Player', 'Games', 'R_TD', 'C_TD', 'INT_TD', 'FR_TD', 'PR_TD', 'KR_TD', 'Other', 'Total', 'XPM', 'FGM', '2PM', 'Safety', 'Points']]\n",
    "\n",
    "ids = ['#passing', '#rushing_and_receiving', '#defense_and_fumbles', '#kicking_and_punting', '#scoring']\n",
    "\n",
    "for i in tqdm(range(len(schools))):\n",
    "    for j in range(len(year)):\n",
    "\n",
    "        data_link = 'https://www.sports-reference.com/cfb/schools/{school}/{year}.html'.format(school = schools[i], year = year[j])\n",
    "        driver.get(data_link)\n",
    "        soup = driver.page_source\n",
    "        soup = BeautifulSoup(soup, 'html.parser')\n",
    "\n",
    "        for k in range(len(ids)):\n",
    "\n",
    "            rows = [[column_n[k]]]\n",
    "\n",
    "            try:\n",
    "                table = soup.select(ids[k])[0]\n",
    "                table_rows = table.find_all('tr')\n",
    "            \n",
    "                row = []\n",
    "                for tr in table_rows:\n",
    "                    td = tr.find_all('td')\n",
    "                    row = [tr.text.strip() for tr in td]\n",
    "                    if row:\n",
    "                        rows.append(row)\n",
    "            except: continue\n",
    "\n",
    "            col_stats[schools[i]][year[j]][ids[k][1:]] = pd.DataFrame(rows[1:] , columns = rows[0]).dropna().reset_index(drop=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "%store col_stats \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [1:09:49<00:00, 31.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "year=tuple(range(2010,2022))\n",
    "\n",
    "column_n = [['Year','College','Player', 'Games', 'Completions', 'Attempts', 'Percentage', 'Yards', 'Y/A', 'AY/A', 'TD', 'INT', 'Rate'],\n",
    "            ['Year','College','Player', 'Games', 'Attempts', 'R_Yards', 'R_AVG', 'R_TD', 'Catches', 'C_Yards', 'C_AVG', 'C_TD', 'S_Plays', 'S_YDS', 'S_AVG' ,'S_TD'],\n",
    "            ['Year','College','Player', 'Games', 'Solo', 'Assist', 'Tot', 'Loss', 'Sack', 'INT', 'INT_Y', 'INT_AVG_Y', 'INT_TD', 'PD', 'Fum_Rec', 'Fum_Y', 'Fum_TD', 'Fum_Forc'],\n",
    "            ['Year','College','Player', 'Games', 'XPM', 'XPA', 'XP%', 'FGM', 'FGA', 'FG%','PTS', 'Punts', 'YDS', 'AVG'],\n",
    "            ['Year','College','Player', 'Games', 'R_TD', 'C_TD', 'INT_TD', 'FR_TD', 'PR_TD', 'KR_TD', 'Other', 'Total', 'XPM', 'FGM', '2PM', 'Safety', 'Points']]\n",
    "\n",
    "ids = ['#passing', '#rushing_and_receiving', '#defense_and_fumbles', '#kicking_and_punting', '#scoring']\n",
    "\n",
    "passing = [column_n[0]] ; rush_rec = [column_n[1]] ; def_fum = [column_n[2]]; kick = [column_n[3]]; scoring = [column_n[4]]\n",
    "\n",
    "for i in tqdm(range(len(schools))):\n",
    "    for j in range(len(year)):\n",
    "\n",
    "        data_link = 'https://www.sports-reference.com/cfb/schools/{school}/{year}.html'.format(school = schools[i], year = year[j])\n",
    "        driver.get(data_link)\n",
    "        soup = driver.page_source\n",
    "        soup = BeautifulSoup(soup, 'html.parser')\n",
    "\n",
    "        for k in range(len(ids)):\n",
    "\n",
    "            rows = []\n",
    "\n",
    "            try:\n",
    "                table = soup.select(ids[k])[0]\n",
    "                table_rows = table.find_all('tr')\n",
    "            \n",
    "                row = []\n",
    "                for tr in table_rows:\n",
    "                    td = tr.find_all('td')\n",
    "                    row = [tr.text.strip() for tr in td]\n",
    "                    if row:\n",
    "                        row.insert(0, schools[i])\n",
    "                        row.insert(0, year[j])\n",
    "                        rows.append(row)\n",
    "            except: continue\n",
    "\n",
    "            if k == 0:\n",
    "                passing.extend(rows)\n",
    "            elif k == 1:\n",
    "                rush_rec.extend(rows)\n",
    "            elif k == 2:\n",
    "                def_fum.extend(rows)\n",
    "            elif k == 3:\n",
    "                kick.extend(rows)\n",
    "            else : scoring.extend(rows)                 \n",
    "        \n",
    "driver.close()\n",
    "\n",
    "passing_df = pd.DataFrame(passing[1:] , columns = passing[0]).dropna().reset_index(drop=True)\n",
    "rush_rec_df = pd.DataFrame(rush_rec[1:] , columns = rush_rec[0]).dropna().reset_index(drop=True)\n",
    "def_fum_df = pd.DataFrame(def_fum[1:] , columns = def_fum[0]).dropna().reset_index(drop=True)\n",
    "kick_df = pd.DataFrame(kick[1:] , columns = kick[0]).dropna().reset_index(drop=True)\n",
    "scoring_df = pd.DataFrame(scoring[1:] , columns = scoring[0]).dropna().reset_index(drop=True)\n",
    "\n",
    "passing_df.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\passing_df.csv', index=False)\n",
    "rush_rec_df.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\rush_rec_df.csv', index=False)\n",
    "def_fum_df.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\def_fum_df.csv', index=False)\n",
    "kick_df.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\kick_df.csv', index=False)\n",
    "scoring_df.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\scoring_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Players where school not in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus Big Board Data revealing communities/Scouts \"value\" of the Player ###\n",
    "--> value does not inclue Team needs --> A team might pass on the best player in the draft (which is a DE, because they need a QB)\n",
    "\n",
    "--> Adjustment for team needs will be done later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "bigboard_url = ['https://www.nflmockdraftdatabase.com/big-boards/2019/consensus-big-board-2016',\n",
    "                'https://www.nflmockdraftdatabase.com/big-boards/2019/consensus-big-board-2017','https://www.nflmockdraftdatabase.com/big-boards/2019/consensus-big-board-2018',\n",
    "                'https://www.nflmockdraftdatabase.com/big-boards/2019/consensus-big-board-2019','https://www.nflmockdraftdatabase.com/big-boards/2020/consensus-big-board-2020',\n",
    "                'https://www.nflmockdraftdatabase.com/big-boards/2021/consensus-big-board-2021', 'https://www.nflmockdraftdatabase.com/big-boards/2022/consensus-big-board-2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_big_boards = []\n",
    "\n",
    "from itertools import chain\n",
    "for i in range(len(bigboard_url)):\n",
    "    res = session.get(bigboard_url[i])\n",
    "    name_selector = res.html.find('.player-name-smaller')\n",
    "\n",
    "    bb = [name_selector[i].element.text for i in range(len(name_selector))]\n",
    "    \n",
    "    year = [2016,2017,2018,2019,2020,2021,2022]\n",
    "    bb = [(*el,year[i]) for el in list(enumerate(bb, start=1))]\n",
    "\n",
    "    con_big_boards.append(bb)\n",
    "\n",
    "con_big_boards = list(chain(*con_big_boards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_big_boards = pd.DataFrame(con_big_boards, columns=['Player_Rank', 'Player', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tyler johnson to tyler johnson 2020\n",
    "con_big_boards.Player[(con_big_boards.Player == \"Tyler Johnson\") & (con_big_boards.Year == 2020)] = \"Tyler Johnson 2020\"\n",
    "con_big_boards.Player[(con_big_boards.Player == \"Jonah Williams\") & (con_big_boards.Year == 2020)] = \"Jonah Williams 2020\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_big_boards.to_excel(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\big_boards2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_big_boards = pd.read_excel(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\big_boards2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team needs to adjust Pick number relative to overall value of the player ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "team_needs_url = [  'https://www.nflmockdraftdatabase.com/team-needs-2016',\n",
    "                    'https://www.nflmockdraftdatabase.com/team-needs-2017','https://www.nflmockdraftdatabase.com/team-needs-2018',\n",
    "                    'https://www.nflmockdraftdatabase.com/team-needs-2019','https://www.nflmockdraftdatabase.com/team-needs-2020',\n",
    "                    'https://www.nflmockdraftdatabase.com/team-needs-2021', 'https://www.nflmockdraftdatabase.com/team-needs-2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_needs = []\n",
    "\n",
    "from itertools import chain\n",
    "for i in range(len(team_needs_url)):\n",
    "    res = session.get(team_needs_url[i])\n",
    "    team_selector = res.html.find('.medium-pick-number')\n",
    "    needs_selector1 = res.html.find('.player-name-smaller')\n",
    "    needs_selector2 = res.html.find('.college-details')\n",
    "\n",
    "    team = [team_selector[i].element.text for i in range(len(team_selector))]\n",
    "    needs1 = [[el.strip() for el in needs_selector1[i].element.text.split(',')] for i in range(len(needs_selector1))]\n",
    "    needs2 = [[el.strip() for el in needs_selector2[i].element.text.split(',')] for i in range(len(needs_selector2))]\n",
    "\n",
    "    needs = [list(chain(*list(el))) for el in zip(needs1,needs2)]\n",
    "\n",
    "    year = [2016,2017,2018,2019,2020,2021,2022]\n",
    "    tn = [(*el,year[i]) for el in list(zip(team,needs))]\n",
    "\n",
    "    team_needs.append(tn)\n",
    "\n",
    "team_needs = list(chain(*team_needs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_needs = pd.DataFrame(team_needs, columns=['Team','Position','Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add team abbreviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTMLSession()\n",
    "abbrev_url = 'https://en.wikipedia.org/wiki/Wikipedia:WikiProject_National_Football_League/National_Football_League_team_abbreviations'\n",
    "\n",
    "res = session.get(abbrev_url)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "table=soup.find('table',{'class':\"wikitable\"})\n",
    "table = pd.read_html(str(table))\n",
    "table = pd.DataFrame(table[0])\n",
    "table.columns = table.iloc[0]\n",
    "table = table.drop(table.index[0]).reset_index(drop=True)\n",
    "\n",
    "#table.to_excel(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\team_abbreviations.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_excel(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\team_abbreviations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_Column = [table.Franchise[table['Commonly Used Abbreviations'] == el].values[0]  for el in team_needs.Team ]\n",
    "team_needs['Franchise'] = team_Column\n",
    "\n",
    "team_needs.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\team_needs2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "team_needs = pd.read_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\team_needs2.csv', converters={'Position' : literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contract/Salary Data from Spotrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--user-data-dir=C:/Users/d_lasc01/AppData/Local/Google/Chrome/User Data/Profile 1')\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "draft_data = pd.read_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\Combined_draft_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_data['Team_Abbrv'] = [ team_needs.Team.drop_duplicates()[team_needs.Franchise.drop_duplicates() == el].values[0] for el in draft_data.NFL_team]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_names = dict([('QB', 'Quarterback'), ('RB','Running Back'),('FB','Fullback'), ('WR','Wide Receiver'), ('TE','Tight End'),('OL','Offensive Lineman'),('C',\t'Center'),('OG', 'Offensive Guard'),('LG','Left Guard'),\n",
    "                  ('RG', 'Right Guard'),('OT', 'Offensive Tackle'),('LT', 'Left Tackle'),('RT','Right Tackle'),('K','Kicker'),('KR','Kick Returner'),('DL', 'Defensive Lineman'),('DE', 'Defensive End'),\n",
    "                  ('DT', 'Defensive Tackle'),('NT', 'Nose Tackle'),('LB', 'Linebacker'),('ILB', 'Inside Linebacker'),('OLB', 'Outside Linebacker'),('MLB', 'Middle Linebacker'),('DB', 'Defensive Back'),\n",
    "                  ('CB'\t,'Cornerback'),('FS', 'Free Safety'),('SS', 'Strong Safety'),('S','Safety'), ('P','Punter'), ('LS','Long Snapper')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = tuple(zip(draft_data.Player, [position_names[draft_data['Pos.'][i]]  for i in range(len(draft_data))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust names in draft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [7:18:14<00:00, 10.28s/it]   \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "contracts = []\n",
    "salary_df = [['Player','Contract_Terms','Signing_Bonus','Average_Salary','GTD_Sign','Total_GTD','Free_Agent']]\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "for i in tqdm(range(len(draft_data))):\n",
    "    try:\n",
    "        driver.get('https://www.spotrac.com/')\n",
    "\n",
    "\n",
    "        e = driver.find_elements_by_css_selector('#search-form input')[0]\n",
    "        e.send_keys(draft_data.Player[i])\n",
    "        e.send_keys(Keys.RETURN)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.url_changes('https://www.spotrac.com/'))\n",
    "\n",
    "        url=driver.current_url\n",
    "            \n",
    "        if ('result' in url) & (len(driver.find_elements_by_css_selector('div.teamitem')) == 0):\n",
    "            e = driver.find_elements_by_css_selector('#search-form input')[0]\n",
    "            e.send_keys(draft_data.Player[i].split()[1])\n",
    "            e.send_keys(Keys.RETURN)\n",
    "\n",
    "            url=\"https://www.spotrac.com/search/results/{search_word}/\".format(search_word=draft_data.Player[i].split()[1])\n",
    "            if EC.url_changes(url):\n",
    "                url = driver.current_url\n",
    "                pass\n",
    "            else: \n",
    "                continue\n",
    "            \n",
    "        if 'result' in url:\n",
    "\n",
    "            search_teams = []\n",
    "            for j in range(len(driver.find_elements_by_css_selector('#main img'))):\n",
    "                search_teams.append(re.findall('/thumb/(.*).png', driver.find_elements_by_css_selector('#main img')[j].get_attribute('src'))[0])\n",
    "\n",
    "            driver.execute_script(\"window.open('https://www.pro-football-reference.com/');\")\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "            d = driver.find_element_by_css_selector(\"form[name='f_big'] input[class='ac-input completely']\")\n",
    "            \n",
    "            d.send_keys(draft_data.Player[i])\n",
    "            d.send_keys(Keys.RETURN)\n",
    "            \n",
    "            url=driver.current_url\n",
    "\n",
    "            try:\n",
    "                if 'search' in url:\n",
    "\n",
    "                    controlls = driver.find_elements_by_css_selector('#players > div > div.search-item-name')\n",
    "                    controlls = [controlls[i].text.split() for i in range(len(controlls))]\n",
    "                    \n",
    "                    match = [(el[0:2] == draft_data.Player[i].split()) & (int(el[3][1:5]) == draft_data.Year[i]) for el in controlls ].index(True) + 2\n",
    "\n",
    "                    driver.find_element_by_css_selector('#players > div:nth-child({no}) > div.search-item-name > a'.format(no = match)).click()\n",
    "\n",
    "                    try:                \n",
    "                        if 'traded' not in driver.find_element_by_css_selector(\"#div_transactions > ul:nth-child(1) > li:nth-child(1)\").text:\n",
    "                            cur_team = driver.find_elements_by_css_selector(\"#div_transactions > ul:nth-child(1) > li:nth-child(1) > a[href]\")                     \n",
    "                            if len(cur_team) == 3:\n",
    "                                cur_team = cur_team[1].text\n",
    "                            else:  cur_team = cur_team[0].text\n",
    "                        else: cur_team = driver.find_element_by_css_selector(\"#div_transactions > ul:nth-child(1) > li:nth-child(1) > a:nth-child(4)\").text\n",
    "                    \n",
    "                    except: cur_team = driver.find_elements_by_css_selector(\"#snap_counts td a\")[-1].get_attribute('title')\n",
    "                    \n",
    "                    cur_team = team_needs.Team[team_needs.Franchise == cur_team].iloc[0]\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "                else: \n",
    "                    try:                \n",
    "                        if 'traded' not in driver.find_element_by_css_selector(\"#div_transactions > ul:nth-child(1) > li:nth-child(1)\").text:\n",
    "                            cur_team = driver.find_elements_by_css_selector(\"#div_transactions > ul:nth-child(1) > li:nth-child(1) > a[href]\")                     \n",
    "                            if len(cur_team) == 3:\n",
    "                                cur_team = cur_team[1].text\n",
    "                            else:  cur_team = cur_team[0].text\n",
    "                        else: cur_team = driver.find_element_by_css_selector(\"#div_transactions > ul:nth-child(1) > li:nth-child(1) > a:nth-child(4)\").text\n",
    "                    \n",
    "                    except: cur_team = driver.find_elements_by_css_selector(\"#snap_counts td a\")[-1].get_attribute('title')\n",
    "                    cur_team = team_needs.Team[team_needs.Franchise == cur_team].iloc[0]\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "            except: \n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "                    continue\n",
    "\n",
    "            idx = [re.sub(r'\\d+$', '', el) for el in search_teams].index(cur_team.lower())\n",
    "            \n",
    "            driver.find_elements_by_css_selector('.team-name')[idx].click()\n",
    "            \n",
    "\n",
    "            contracts = driver.find_elements_by_xpath('//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"playerValue\", \" \" ))]')\n",
    "\n",
    "            composite_list = [contracts[x:x+6] for x in range(0, len(contracts),6)]\n",
    "\n",
    "            for list in composite_list:\n",
    "                row = []\n",
    "                row.append(draft_data.Player[i])\n",
    "                \n",
    "                for el in list:\n",
    "                    row.append(el.text)\n",
    "                salary_df.append(row)\n",
    "\n",
    "        else:\n",
    "\n",
    "            contracts = driver.find_elements_by_xpath('//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"playerValue\", \" \" ))]')\n",
    "\n",
    "            composite_list = [contracts[x:x+6] for x in range(0, len(contracts),6)]\n",
    "\n",
    "            for list in composite_list:\n",
    "                row = []\n",
    "                row.append(draft_data.Player[i])\n",
    "                \n",
    "                for el in list:\n",
    "                    row.append(el.text)\n",
    "                salary_df.append(row)\n",
    "\n",
    "    except: continue\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_salary = pd.DataFrame(salary_df[1:], columns=salary_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player_salary.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\player_salary.csv', index=False)\n",
    "player_salary = pd.read_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\player_salary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = draft_data[[el not in list(player_salary.Player) for el in draft_data.Player]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "contracts = []\n",
    "salary_df2 = [['Player','Contract_Terms','Signing_Bonus','Average_Salary','GTD_Sign','Total_GTD','Free_Agent']]\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "for i in missing.index:\n",
    "    \n",
    "    try:\n",
    "        driver.get('https://www.spotrac.com/')\n",
    "\n",
    "\n",
    "        e = driver.find_elements_by_css_selector('#search-form input')[0]\n",
    "        e.send_keys(missing.Player[i])\n",
    "        e.send_keys(Keys.RETURN)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.url_changes('https://www.spotrac.com/'))\n",
    "\n",
    "        url=driver.current_url\n",
    "            \n",
    "                   \n",
    "        if 'result' in url:\n",
    "\n",
    "            search_teams = []\n",
    "            #for j in range(len(driver.find_elements_by_css_selector('#main img'))):\n",
    "            #    search_teams.append(re.findall('/thumb/(.*).png', driver.find_elements_by_css_selector('#main img')[j].get_attribute('src'))[0])\n",
    "\n",
    "            for j in range(len(driver.find_elements_by_css_selector('div.teamitem'))):\n",
    "\n",
    "                driver.find_elements_by_css_selector('.team-name')[j].click()\n",
    "                \n",
    "                logo = []\n",
    "                for k in range(len(driver.find_elements_by_css_selector('#contracts > table > tbody > tr > td > div > h2'))):\n",
    "                    logo.append(re.sub(r'[0-9]+', '', re.findall('/thumb/(.*).png', driver.find_elements_by_css_selector('#contracts > table > tbody > tr > td > div > h2 > span.contract-type-logo > img')[k].get_attribute('src'))[0]))\n",
    "            \n",
    "                if team_needs.Franchise[team_needs.Team == logo[-1].upper()].unique()[0] == missing.NFL_team[i]:\n",
    "\n",
    "                    contracts = driver.find_elements_by_xpath('//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"playerValue\", \" \" ))]')\n",
    "\n",
    "                    composite_list = [contracts[x:x+6] for x in range(0, len(contracts),6)]\n",
    "\n",
    "                    for lst in composite_list:\n",
    "                        row = []\n",
    "                        row.append(draft_data.Player[i])\n",
    "                        \n",
    "                        for el in lst:\n",
    "                            row.append(el.text)\n",
    "                        salary_df2.append(row)\n",
    "\n",
    "                else: driver.back()\n",
    "\n",
    "    except: continue\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.extend(salary_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_salary = pd.DataFrame(salary_df[1:], columns=salary_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = draft_data[[el not in list(player_salary.Player) for el in draft_data.Player]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_salary.to_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\player_salary.csv', index=False)\n",
    "#player_salary = pd.read_csv(r'C:\\Users\\d_lasc01\\OneDrive - Universität Münster\\6. Promotion\\COVID and Sports\\player_salary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'salary_df3' (list)\n"
     ]
    }
   ],
   "source": [
    "%store salary_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get('https://www.spotrac.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts = driver.find_elements_by_xpath('//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"playerValue\", \" \" ))]')\n",
    "\n",
    "composite_list = [contracts[x:x+6] for x in range(0, len(contracts),6)]\n",
    "\n",
    "for lst in composite_list:\n",
    "    row = []\n",
    "    row.append(missing.Player[2181])\n",
    "    \n",
    "    for el in lst:\n",
    "        row.append(el.text)\n",
    "    salary_df3.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping draftscout data --> no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import selenium\n",
    "import bs4\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "position = [ 'QB', 'RB', 'FB', 'TE', 'WR', 'C', 'OT', 'OG', 'K', 'DE', 'DT', 'ILB', 'OLB', 'CB', 'FS', 'SS', 'P' ]\n",
    "year = [2019,2020]\n",
    "#pos_ranking_url = 'https://draftscout.com/players{yr}.php?GenPos={pos}&DraftYear={yr}&sortorder=TSXPos&order=ASC'.format(pos = position[i], yr = year[j])\n",
    "\n",
    "pos_ranking = pd.DataFrame([],columns=[\"Rank\",\"Tier\",\"Player Name\", 'College', 'Proj High','Projected','Proj Low', 'Height', 'Weight', '40 Time Range', 'Hometown, State', 'High School','Position','Year'])\n",
    "\n",
    "for i in range(len(position)):\n",
    "    for j in range(len(year)):\n",
    "        driver = webdriver.Chrome()\n",
    "        pos_ranking_url = 'https://draftscout.com/players{yr}.php?GenPos={pos}&DraftYear={yr}&sortorder=TSXPos&order=ASC'.format(pos = position[i], yr = year[j])\n",
    "      \n",
    "        driver.get(pos_ranking_url)\n",
    "\n",
    "        # Obtain the number of rows in body\n",
    "        rows = len(driver.find_elements_by_xpath(\"/html/body/font/b/div/div/table/tbody/tr/td/table/tbody/tr/td/table/tbody/tr\")) -1\n",
    "        cols=len(driver.find_elements_by_xpath(\"/html/body/font/b/div/div/table/tbody/tr/td/table/tbody/tr/td/table/tbody/tr/td\")) -1\n",
    "        elements = driver.find_elements_by_xpath(\"/html/body/font/b/div/div/table/tbody/tr/td/table/tbody/tr/td/table/tbody/tr/td\")[1:]\n",
    "\n",
    "        df=[]\n",
    "        for r in range(0,rows):\n",
    "            row = []\n",
    "            for c in range(0, int(cols/rows)):\n",
    "                row.append(elements[c+list(range(cols+1))[0::int(cols/rows)][r]].text)\n",
    "                df.append(row)\n",
    "\n",
    "        \n",
    "\n",
    "        df = pd.DataFrame(df,columns=[\"Rank\",\"Tier\",\"Player Name\", 'College', 'Proj High','Projected','Proj Low', 'Height', 'Weight', '40 Time Range', 'Hometown, State', 'High School'])\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Position'] = position[i]\n",
    "        df['Year'] = year[j]\n",
    "\n",
    "        pos_ranking = pos_ranking.append(df)\n",
    "\n",
    "        driver.close()\n",
    "\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e2529bebb4a2f0e179de5dfbb9c7a693ca9e76c59dbd963bce143ddf049a928"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
